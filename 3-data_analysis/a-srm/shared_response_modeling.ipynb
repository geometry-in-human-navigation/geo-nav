{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared response modeling\n",
    "We project fMRI responses from each subject (20 subjects in total) into a shared low-dimensional space across 180 brain regions.\n",
    "- [The shared response model](https://papers.nips.cc/paper/5855-a-reduced-dimension-fmri-shared-response-model) aims to learn this shared feature space.\n",
    "- SRM can be summarized graphically from [Cohen et al., 2017](https://www.nature.com/articles/nn.4499)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. mask epi data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set mask epi data env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import os \n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.spatial.distance as sp_distance\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "from brainiak.isc import isc\n",
    "from brainiak.fcma.util import compute_correlation\n",
    "import brainiak.funcalign.srm\n",
    "from brainiak import image, io\n",
    "import brainiak\n",
    "\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import glob\n",
    "from nilearn.input_data import NiftiMasker,  MultiNiftiMasker\n",
    "from nilearn.image import concat_imgs, index_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "\n",
    "%autosave 5\n",
    "%matplotlib inline\n",
    "\n",
    "project_dir=\"/media/statespace/Spatial/sptialworkspace/spatialfMRI/fMRI_analysis/igeo_process\"\n",
    "fMRI_data_dir=\"/media/statespace/Spatial/sptialworkspace/spatialfMRI/fMRI_data/spatialfMRI_nii\"\n",
    "\n",
    "preprocessed_dir=project_dir+\"/preprocess/preprocessed/afni_2023\"\n",
    "processed_dir=project_dir+\"/process/processed\"\n",
    "\n",
    "num_runs = 14\n",
    "num_TRs = 223\n",
    "num_midlayer_units = 8\n",
    "num_layer_pca_components = 20\n",
    "num_deeplayers_units = num_midlayer_units + 12*num_layer_pca_components\n",
    "num_semantic_categories = 10\n",
    "\n",
    "start_fixation_TRs = 3\n",
    "hemodynamic_shift_TRs = 3\n",
    "num_TRs_video = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load atlas brain regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# read design matrix\n",
    "atlas_labels_txt = \"Atlas MNI_Glasser_HCP_v1.0, 360 regions.txt\"\n",
    "atlas_labels_file = os.path.join(project_dir, \"process/depth/mni_glasser_hcp\", atlas_labels_txt)\n",
    "\n",
    "in_file = open(atlas_labels_file,'r')\n",
    "brain_region_dict={}\n",
    "\n",
    "# distinguish left and right brain regions\n",
    "atlas_all_lines = in_file.readlines()\n",
    "\n",
    "for i_line in range(0,len(atlas_all_lines)):\n",
    "    if \"u:L_\" in atlas_all_lines[i_line]:\n",
    "        \n",
    "        atlas_brain_region_label = []\n",
    "\n",
    "        # left brain regions\n",
    "        atlas_line_left = atlas_all_lines[i_line]\n",
    "        atlas_temp = atlas_line_left.split(\":\")\n",
    "        atlas_brain_region_name = atlas_temp[1][2:]\n",
    "        # print(atlas_brain_region_name)\n",
    "        atlas_brain_region_label_left = int(atlas_temp[2][:-1])\n",
    "        atlas_brain_region_label.append(atlas_brain_region_label_left)\n",
    "        \n",
    "        # right brain regions\n",
    "        atlas_line_right = atlas_all_lines[i_line+1]\n",
    "        atlas_temp = atlas_line_right.split(\":\")\n",
    "        atlas_brain_region_name = atlas_temp[1][2:]\n",
    "        atlas_brain_region_label_right = int(atlas_temp[2][:-1])\n",
    "        atlas_brain_region_label.append(atlas_brain_region_label_right)\n",
    "\n",
    "        # put into dict\n",
    "        brain_region_dict[atlas_brain_region_name] = atlas_brain_region_label\n",
    "\n",
    "# print(len(brain_region_dict),brain_region_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_name_list = list(brain_region_dict.keys())\n",
    "brain_region_label_list = list(brain_region_dict.values())\n",
    "\n",
    "folder_list = [\"sub-01\", \"sub-02\", \"sub-03\", \"sub-04\", \"sub-05\", \n",
    "               \"sub-06\", \"sub-07\", \"sub-08\", \"sub-09\", \"sub-10\", \n",
    "               \"sub-11\", \"sub-12\", \"sub-13\", \"sub-14\", \"sub-15\",\n",
    "               \"sub-16\", \"sub-17\", \"sub-18\", \"sub-19\", \"sub-20\",\n",
    "               ]\n",
    "\n",
    "num_subs = len(folder_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create region-based masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_brain_region_name in np.arange(0, len(brain_region_name_list)):\n",
    "  \n",
    "  brain_region_name = brain_region_name_list[i_brain_region_name]\n",
    "\n",
    "  for sub_name in folder_list:\n",
    "\n",
    "    mask_name = sub_name+\"_MNI_Glasser_HCP_neural_mask.nii.gz\"\n",
    "    mask_file = os.path.join(processed_dir, sub_name, \"shared_regions\", mask_name)\n",
    "\n",
    "    # Load the mask image\n",
    "    mask = nib.load(mask_file)\n",
    "    mask_data = mask.get_data()\n",
    "\n",
    "    if i_brain_region_name != 0: # remove the effect of first region V1, id V1 is same as mask 0\n",
    "      mask_data[mask_data==1] = 0\n",
    "\n",
    "    for i_num_region in brain_region_label_list[i_brain_region_name]:\n",
    "        mask_data[mask_data==i_num_region] = 1\n",
    "\n",
    "    mask_data[mask_data!=1] = 0\n",
    "\n",
    "    voxel_num = np.count_nonzero(mask_data[mask_data!=0])\n",
    "    # print(voxel_num)\n",
    "\n",
    "    mask_nifti = nib.Nifti1Image(mask_data, mask.affine, mask.header)\n",
    "\n",
    "    saved_mask_name = sub_name + \"_\" + brain_region_name+\"_MNI_Glasser_HCP_neural_mask.nii.gz\"\n",
    "\n",
    "    mask_path = os.path.join(processed_dir, sub_name, \"shared_regions\", saved_mask_name)\n",
    "\n",
    "    nib.save(mask_nifti, mask_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask the epi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_masked_epi_data_list = []\n",
    "\n",
    "for sub_name in folder_list:\n",
    "  \n",
    "  # print('sub name:',sub_name)\n",
    "\n",
    "  brain_region_epi_data_list = []\n",
    "\n",
    "  for brain_region_name in brain_region_name_list:\n",
    "\n",
    "    print('sub name:',sub_name,',brain_region_name:',brain_region_name)\n",
    "\n",
    "    ### load mask\n",
    "    mask_name = sub_name + \"_\" + brain_region_name+\"_MNI_Glasser_HCP_neural_mask.nii.gz\"\n",
    "    mask_file = os.path.join(processed_dir, sub_name, \"shared_regions\", mask_name)\n",
    "\n",
    "    # Load the mask image\n",
    "    mask = nib.load(mask_file)\n",
    "\n",
    "    mask_data = mask.get_data()\n",
    "    \n",
    "    voxel_num = np.count_nonzero(mask_data[mask_data!=0])\n",
    "    # mask = nib.Nifti1Image(mask_data, affine=np.eye(4))\n",
    "\n",
    "    sub_masked_data = np.empty((voxel_num,0), float)\n",
    "\n",
    "    sub_dir = os.path.join(processed_dir, sub_name)\n",
    "\n",
    "    for run in range(1, num_runs+1):\n",
    "\n",
    "      # load epi data\n",
    "      current_file_str = 'pb04.{subject}.r{run:02}.combine+demean.nii.gz'\n",
    "      current_wildcard_file_name = os.path.join(sub_dir, \"shared_regions\", current_file_str.format(subject=sub_name,run=run))\n",
    "\n",
    "      current_file_name = glob.glob(current_wildcard_file_name)[0]\n",
    "      epi_data = nib.load(current_file_name)\n",
    "\n",
    "      epi_data = index_img(epi_data, slice(0, num_TRs))\n",
    "\n",
    "      # print(sub_name,\"run\", run, epi_data.shape)\n",
    "\n",
    "      # mask bold signal\n",
    "      nifti_masker = NiftiMasker(mask_img=mask)\n",
    "      masked_data = nifti_masker.fit_transform(epi_data)\n",
    "      masked_data = masked_data.T\n",
    "\n",
    "      # do it for epi data\n",
    "      masked_data = stats.zscore(masked_data, axis=1, ddof=1)\n",
    "      masked_data = np.nan_to_num(masked_data)\n",
    "      # print(\"masked_data shape (voxel_num,TR_num)\", masked_data.shape)\n",
    "\n",
    "      sub_masked_data = np.append(sub_masked_data, masked_data, axis=1)\n",
    "\n",
    "    # add a brain region\n",
    "    brain_region_epi_data_list.append(sub_masked_data)\n",
    "\n",
    "  # add a subject\n",
    "  sub_masked_epi_data_list.append(brain_region_epi_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of subjects:\", len(sub_masked_epi_data_list))\n",
    "print(\"num of brain regions:\", len(sub_masked_epi_data_list[0]))\n",
    "\n",
    "for i in range(0, len(brain_region_name_list)):\n",
    "    print(folder_list[0],',',brain_region_name_list[i],':',sub_masked_epi_data_list[0][i].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and load sub_masked_epi_data_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "\n",
    "matdic = {\"sub_masked_epi_data_list\":sub_masked_epi_data_list}\n",
    "file_dir = processed_dir+\"/depth/temp_data/\"\n",
    "hdf5storage.savemat(file_dir+\"sub_masked_epi_data_list.mat\", matdic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5storage\n",
    "\n",
    "file_dir = processed_dir+\"/depth/temp_data/\"\n",
    "matdic = hdf5storage.loadmat(file_dir+\"sub_masked_epi_data_list.mat\", )\n",
    "\n",
    "sub_masked_epi_data_list = matdic[\"sub_masked_epi_data_list\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of subjects:\", len(sub_masked_epi_data_list))\n",
    "print(\"num of brain regions:\", len(sub_masked_epi_data_list[0]))\n",
    "\n",
    "for i in range(0, len(brain_region_name_list)):\n",
    "    print(folder_list[0],',',brain_region_name_list[i],':',sub_masked_epi_data_list[0][i].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. set feature dimensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set feature dimensions by The Optimal Hard Threshold\n",
    "\n",
    "The optimal hard threshold for singular values is 4 / sqrt(3)\n",
    "\n",
    "1.https://github.com/brainiak/brainiak/blob/ee093597c6c11597b0a59e95b48d2118e40394a5/brainiak/reprsimil/brsa.py#L157\n",
    "2.http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate averaged feature dimensions by The Optimal Hard Threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiak.reprsimil.brsa import Ncomp_SVHT_MG_DLD_approx\n",
    "\n",
    "regions_average_dims_list  = []\n",
    "\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "\n",
    "  region_dims_list = []\n",
    "\n",
    "  for i_sub in range(0, num_subs):\n",
    "\n",
    "    temp_masked_epi_data = sub_masked_epi_data_list[i_sub][i_region]\n",
    "    ncomp = Ncomp_SVHT_MG_DLD_approx(temp_masked_epi_data.T) # 2-D numpy array of size [n_T, n_V]\n",
    "    region_dims_list.append(ncomp)\n",
    "\n",
    "  average_dims = np.mean(np.asarray(region_dims_list))\n",
    "  regions_average_dims_list.append(np.floor(average_dims).astype(int))\n",
    "\n",
    "regions_average_dims_array = np.asarray(regions_average_dims_list)\n",
    "print(\"regions_average_dims_array:\",regions_average_dims_array)\n",
    "\n",
    "print(\"features in total:\", np.sum(regions_average_dims_array))\n",
    "plt.hist(regions_average_dims_array, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterate feature dimensions with equal distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dims = np.sum(regions_average_dims_array) # average each subject regions from Ncomp_SVHT_MG_DLD_approx\n",
    "num_total_regions = 180 # 180 together\n",
    "num_samples = 100\n",
    "\n",
    "brain_region_dim_equal_div_array = np.linspace(num_total_regions, num_total_dims, num_samples)\n",
    "\n",
    "brain_region_dim_scale_list = []\n",
    "for i in brain_region_dim_equal_div_array:\n",
    "  brain_region_dim_scale_list.append(num_total_dims/i)\n",
    "\n",
    "# brain_region_dim_scale_list = brain_region_dim_scale_list[1:] # remove 180 \n",
    "num_total_dims_list = []\n",
    "\n",
    "# scale dims\n",
    "for i_brain_region_dim_scale in brain_region_dim_scale_list:\n",
    "\n",
    "  brain_region_dim_scale = i_brain_region_dim_scale \n",
    "  region_voxels_array = np.rint(copy.deepcopy(regions_average_dims_array)/brain_region_dim_scale).astype(int)\n",
    "  num_total_dims = np.sum(region_voxels_array)\n",
    "  # print(\"dims in total (with zero dims):\", num_total_dims)\n",
    "  # print(\"dims in total:\", num_total_dims, \",\", region_voxels_array)\n",
    "\n",
    "  region_voxels_array[region_voxels_array == 0] = 1\n",
    "  srm_dim_max = np.max(region_voxels_array)\n",
    "  srm_dim_min = np.min(region_voxels_array)\n",
    "\n",
    "  num_total_dims = np.sum(region_voxels_array)\n",
    "  print(\"dims in total:\", num_total_dims, \",\", region_voxels_array)\n",
    "  print(\"max:\", srm_dim_max, \",min\", srm_dim_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select the feature dimension with max number of effective regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total_dims = np.sum(regions_average_dims_array) # average each subject regions from Ncomp_SVHT_MG_DLD_approx\n",
    "num_total_regions = 180 # 180 together\n",
    "num_samples = 100\n",
    "\n",
    "brain_region_dim_equal_div_array = np.linspace(num_total_regions, num_total_dims, num_samples)\n",
    "\n",
    "brain_region_dim_scale_list = []\n",
    "for i in brain_region_dim_equal_div_array:\n",
    "  brain_region_dim_scale_list.append(num_total_dims/i)\n",
    "  \n",
    "# index_max_num_significant_regions equals to 23, 1409\n",
    "index_max_num_significant_regions = 23\n",
    "\n",
    "# scale dims\n",
    "print(\"brain_region_dim_scale:\", brain_region_dim_scale_list[index_max_num_significant_regions])\n",
    "brain_region_dim_scale = brain_region_dim_scale_list[index_max_num_significant_regions] \n",
    "region_voxels_array = np.rint(copy.deepcopy(regions_average_dims_array)/brain_region_dim_scale).astype(int)\n",
    "num_total_dims = np.sum(region_voxels_array)\n",
    "# print(\"dims in total (with zero dims):\", num_total_dims)\n",
    "# print(\"dims in total:\", num_total_dims, \",\", region_voxels_array)\n",
    "region_voxels_array[region_voxels_array == 0] = 1\n",
    "srm_dim_max = np.max(region_voxels_array)\n",
    "srm_dim_min = np.min(region_voxels_array)\n",
    "\n",
    "num_total_dims = np.sum(region_voxels_array)\n",
    "print(\"dims in total:\", num_total_dims)\n",
    "# print(\"region_voxels_array:\", region_voxels_array)\n",
    "print(\"max:\", srm_dim_max, \",min\", srm_dim_min)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and save \"region_voxels_array\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "import copy\n",
    "\n",
    "print(\"region_voxels_array shape:\", region_voxels_array.shape)\n",
    "\n",
    "matdic = {\"region_voxels_array\": region_voxels_array}\n",
    "project_dir=\"/media/statespace/Spatial/sptialworkspace/spatialfMRI/fMRI_analysis/igeo_process\"\n",
    "\n",
    "file_dir = project_dir+\"/process/depth/temp_data/\"\n",
    "savemat(file_dir + \"vit_\"+ str(num_total_dims) + \"_dims\" +\"_region_voxels_array.mat\", matdic)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region_voxels_array shape = (180,)\n",
      "max: 36 ,min 1\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "project_dir=\"/media/statespace/Spatial/sptialworkspace/spatialfMRI/fMRI_analysis/igeo_process\"\n",
    "file_dir = project_dir+\"/process/depth/temp_data/\"\n",
    "matdic = loadmat(file_dir + \"vit_\"+ str(num_total_dims) + \"_dims\" +\"_region_voxels_array.mat\")\n",
    "\n",
    "region_voxels_array = np.squeeze(matdic[\"region_voxels_array\"])\n",
    "print(\"region_voxels_array shape =\", region_voxels_array.shape)\n",
    "\n",
    "srm_dim_max = np.max(region_voxels_array)\n",
    "srm_dim_min = np.min(region_voxels_array)\n",
    "print(\"max:\", srm_dim_max, \",min\", srm_dim_min)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting into train and test data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "\n",
    "  each_region_train_data = []\n",
    "  each_region_test_data = []\n",
    "\n",
    "  for i_sub in range(0, num_subs):\n",
    "\n",
    "    temp_masked_epi_data = sub_masked_epi_data_list[i_sub][i_region]\n",
    "\n",
    "    temp_train_epi_data = np.concatenate((temp_masked_epi_data[:,0:223*10], temp_masked_epi_data[:,223*13:223*14]), axis=1)\n",
    "\n",
    "    temp_test_epi_data = temp_masked_epi_data[:,223*10:223*13]\n",
    "\n",
    "    each_region_train_data.append(temp_train_epi_data)\n",
    "    each_region_test_data.append(temp_test_epi_data)\n",
    "\n",
    "  train_data.append(each_region_train_data)\n",
    "  test_data.append(each_region_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_data shape:', np.asarray(train_data).shape)\n",
    "print('train_data shape:', np.asarray(train_data[0][0]).shape)\n",
    "print('test_data shape:', np.asarray(test_data).shape)\n",
    "print('test_data shape:', np.asarray(test_data[0][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srm_list = []\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "\n",
    "  temp_train_data = train_data[i_region]\n",
    "  features = 10  # features\n",
    "  n_iter = 200  # iterations of fitting\n",
    "\n",
    "  # Create the SRM object\n",
    "  srm = brainiak.funcalign.srm.SRM(n_iter=n_iter, features=features)\n",
    "\n",
    "  # Fit the SRM data\n",
    "  print(brain_region_name_list[i_region], ' Fitting...')\n",
    "  srm.fit(temp_train_data)\n",
    "  print(brain_region_name_list[i_region], ' SRM has been fit.')\n",
    "\n",
    "  srm_list.append(srm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the shared response model by regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting into train and test data\n",
    "train_data = []\n",
    "\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "\n",
    "  each_region_train_data = []\n",
    "\n",
    "  for i_sub in range(0, num_subs):\n",
    "\n",
    "    temp_masked_epi_data = sub_masked_epi_data_list[i_sub][i_region]\n",
    "\n",
    "    each_region_train_data.append(temp_masked_epi_data)\n",
    "\n",
    "  train_data.append(each_region_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srm_list = []\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "\n",
    "  temp_train_data = train_data[i_region]\n",
    "  n_iter = 200  # iterations of fitting\n",
    "\n",
    "  features = region_voxels_array[i_region]\n",
    "  # Create the SRM object\n",
    "  srm = brainiak.funcalign.srm.SRM(n_iter=n_iter, features=features)\n",
    "\n",
    "  # Fit the SRM data\n",
    "  print(brain_region_name_list[i_region], ' Fitting...')\n",
    "  srm.fit(temp_train_data)\n",
    "  # print(brain_region_name_list[i_region], ' SRM has been fit.')\n",
    "\n",
    "  srm_list.append(srm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save shared response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "import copy\n",
    "\n",
    "semgeo_shared_glm_list = []\n",
    "\n",
    "for i_region in range(0, len(brain_region_name_list)):\n",
    "  shared_response = copy.deepcopy(srm_list[i_region].s_)\n",
    "  # print(brain_region_name_list[i_region], shared_response.shape)\n",
    "  semgeo_shared_glm_list.append(shared_response)\n",
    "\n",
    "print(\"num_total_dims:\", num_total_dims)\n",
    "matdic = {\"semgeo_shared_glm_list\":semgeo_shared_glm_list}\n",
    "file_dir = project_dir+\"/process/depth/temp_data/\"\n",
    "savemat(file_dir + \"vit_\"+ str(num_total_dims) + \"_dims\" +\"_semgeo_shared_glm_list_optimal_hard_threshold.mat\", matdic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mybrainiak')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec7d6cffe7c6d14e69b93d0be414579ffb6d386eea0c209e781b05305021d8ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
